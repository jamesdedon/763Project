{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read xlsx data and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "# import graphviz\n",
    "\n",
    "datafile = pd.read_excel('atus/ehresp_2014.xlsx')\n",
    "#column_names = ['eeincome1', 'erhhch', 'erincome', 'erspemch', 'ertpreat', 'ertseat', 'eudietsoda', 'eudrink', 'eueat', 'euexercise', 'euexfreq', 'eufastfd', 'eufastfdfrq', 'euffyday', 'eufdsit', 'eufinlwgt', 'eusnap', 'eugroshp', 'euinclvl', 'euincome2', 'eumeat', 'eumilk', 'euprpmel', 'eusoda', 'eustores', 'eustreason', 'eutherm', 'euwic', 'exincome1', 'eugenhth', 'erbmi']\n",
    "#target_column_name = 'erbmi'\n",
    "#dataset = load[column_names]\n",
    "#print(dataset.shape)\n",
    "#print(dataset[0:3])\n",
    "#dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace all nonvalid value codes with 0 and remove all rows where the BMI or GenHealth data is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1141523b96d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatafile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mempty_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'erbmi'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eugenhth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mempty_rows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# works on datafile, result is dataset\n",
    "\n",
    "dataset = datafile.applymap(lambda x: max(x,0))\n",
    "empty_rows = list()\n",
    "for i in range(df.shape[0]):\n",
    "    if dataset.iloc[i]['erbmi'] == 0 or dataset.iloc[i]['eugenhth']==0:\n",
    "        empty_rows.append(i)\n",
    "dataset.drop(index=empty_rows, inplace=True)\n",
    "dataset.dropna(axis=0,subset=['erbmi','eugenhth'],inplace=True)\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "#df.shape\n",
    "#df.loc[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset['erbmi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create column 'bmi' by categorizing data in 'erbmi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bmi_intlabel(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    elif x < 18.5:\n",
    "        return 1\n",
    "    elif x < 25:\n",
    "        return 2\n",
    "    elif x < 30:\n",
    "        return 3\n",
    "    return 4\n",
    "\n",
    "bmi_labels=[\"Unreported\",\"Underweight\",\"Healthy\",\"Overweight\",\"Obese\"]\n",
    "hthlabels = [\"Unreported\", \"Excellent\", \"Very Good\", \"Good\", \"Fair\",\"Poor\"]\n",
    "\n",
    "bmi_data = list()\n",
    "for i in range(dataset.shape[0]):\n",
    "    bmi_data.append(int(bmi_intlabel(dataset.iloc[i]['erbmi'])))\n",
    "\n",
    "df_temp = pd.DataFrame({\"bmi\": pd.Series(bmi_data)})\n",
    "#df_temp.astype('int32',copy=True)\n",
    "dataset = pd.concat([dataset,df_temp],axis=1,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset[10600:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Column 'income' from column 'erincome'\n",
    "(erincome combines data from two different questions, but it's values of 2,3, and 4 are hard to differentiate, so combine into one value of 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "income_data = list()\n",
    "for i in range(dataset.shape[0]):\n",
    "    income = int(dataset.iloc[i]['erincome'])\n",
    "    if income == 3 or income == 4:\n",
    "        income = 2\n",
    "    income_data.append(income)\n",
    "df_temp = pd.DataFrame({\"income\": income_data})\n",
    "dataset = pd.concat([dataset,df_temp],axis=1,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset.iloc[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to One Hot Encode selected categorical columns from a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot_categorical_columns(file, columns):\n",
    "    # Adapted from prepare_categorical_columns in Eric Heilander's prepareData notebook   \n",
    "    # Extract columns from file; convert to array\n",
    "    dataset = file[columns]\n",
    "    \n",
    "    # Apply LabelEncoder to multiple columns: https://stackoverflow.com/a/31939145\n",
    "    dataset = pd.DataFrame(dataset).apply(LabelEncoder().fit_transform)\n",
    "\n",
    "    # OHE for multiple columns using pd.get_dummies: https://stackoverflow.com/a/44601764\n",
    "    # Another get_dummies example: http://queirozf.com/entries/one-hot-encoding-a-feature-on-a-pandas-dataframe-an-example\n",
    "    # OHE vs. get_dummies: https://medium.com/@guaisang/handling-categorical-features-get-dummies-onehotencoder-and-multicollinearity-f9d473a40417\n",
    "    dataset_df = pd.DataFrame(dataset, columns=columns)\n",
    "    # Keep only the columns we want, and drop the extraneous dummy column\n",
    "    dataset_dummies = pd.get_dummies(dataset_df,\n",
    "                                     columns=columns,\n",
    "                                     drop_first=True)\n",
    "    dataset = dataset_dummies\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onehot categorical columns  and remerge with numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerical_columns = ['ertpreat', # total amount of time spent in primary eating and drinking \\\n",
    "                     'ertseat',  # time spent in secondary eating \\\n",
    "                     'euexfreq',  # reported number of times exercised in last week \\\n",
    "                     'eufastfdfrq']  # reported number of times buying fast food or prepared food \n",
    "                     #'euhgt', \\ # reported height. Already a factor in BMI, so no gain from including\n",
    "                     #'euwgt'] # reported weight. Already a factor in BMI, so not gain from including\n",
    "\n",
    "categorical_columns = [#'eeincome1',  # is income greater than, less than, or equal to 185% of poverty threshold \\\n",
    "                       'erhhch',  # Change in Household composition \\\n",
    "                       #'erincome',  # replaced with income column \\\n",
    "                       'erspemch',  # change in spouse's employment\n",
    "                       #'ethgt',  # topcode flag, is metadata\n",
    "                       #'etwgt',  # topcode flag, is metadata\n",
    "                       'eudietsoda',  # Was the softdrink diet, regular, or both\n",
    "                       'eudrink',  # Did you drink non-water beveridges yesterday\n",
    "                       'eueat',  # Did you eat or drink while doing something else ?\n",
    "                       'euexercise', # Did you exercise in the last week ?\n",
    "                       'eufastfd',  # Did you eat any fast food last week \n",
    "                       'euffyday',  # Did you eat fast food yesterday ?\n",
    "                       'eufdsit',  # Did you get enough to eat yesterday ?\n",
    "                       'eusnap',  # Did anyone in your household get food stamps ?\n",
    "                       #'eugenhth',  # Is a target\n",
    "                       'eugroshp',  # Are you the primary grocery shopper ?\n",
    "                       #'euinclvl',  # Which year's primary threshold was used\n",
    "                       #'euincome2',  # incomed compared to 130% of poverty\n",
    "                       'eumeat',  # Did you eat meat last week ?\n",
    "                       'eumilk',  # Did you drink or serve raw milk ?\n",
    "                       'euprpmel',  # Are you the main cook in your household ?\n",
    "                       'eusoda',  # Did you drink soft drinks ?\n",
    "                       'eustores',  # At what kind of store do you buy groceries ?\n",
    "                       'eustreason',  # Why ?\n",
    "                       'eutherm',  # Do you use a meat thermometer ?\n",
    "                       'euwic',  # Did you get WIC benefits ?\n",
    "                       'bmi', # categorized bmi\n",
    "                       'income']\n",
    "\n",
    "one_df = onehot_categorical_columns(dataset,categorical_columns)\n",
    "numerical_df = dataset.loc[:,numerical_columns]\n",
    "merged_df = pd.concat([numerical_df, one_df],axis=1,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_df[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Decision Tree Classifier using 'genhth' as the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "hth_Xtrain, hth_Xtest, hth_ytrain, hth_ytest = train_test_split(merged_df, dataset['eugenhth'], test_size = 0.1)\n",
    "#print(X_cols)\n",
    "#X_cols.remove('eugenhth')\n",
    "#X_cols.remove('genhth')\n",
    "#X_cols.remove('bmi')\n",
    "#X_cols.remove('eufinlwgt')\n",
    "#X_cols.remove('erbmi')\n",
    "#X['erincome'] = X['erincome'].astype('category')\n",
    "#X = data.loc[:,X_cols]\n",
    "#X=X.dropna(how='any')\n",
    "#X\n",
    "#y = data['genhth']\n",
    "#y\n",
    "#hth_classifier = tree.DecisionTreeClassifier(criterion='entropy',max_depth=3)\n",
    "hth_classifier = tree.DecisionTreeClassifier(max_depth = 5)\n",
    "hth_classifier.fit(hth_Xtrain, hth_ytrain)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(hth_ytest, hth_classifier.predict(hth_Xtest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display a decision tree showing the major predictors of general health "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(hth_classifier,feature_names=merged_df.columns,class_names=hthlabels[0:],filled=True, rounded=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "#graph.render(\"BMI\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a classifier to predict BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bmi_columns = [x for x in merged_df.columns if 'bmi' not in x]\n",
    "bmi_X = merged_df.loc[:,bmi_columns]\n",
    "#bmi_Xtrain, bmi_Xtest, bmi_ytrain, bmi_ytest = train_test_split(merged_df.loc[:,bmi_columns], dataset['bmi'], test_size = 0.1)\n",
    "bmi_classifier = tree.DecisionTreeClassifier(max_depth=5)\n",
    "bmi_classifier.fit(bmi_X, dataset['bmi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bmi_X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display a decision tree showing the major predictors of BMI classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bmi_dot_data = tree.export_graphviz(bmi_classifier,feature_names=bmi_Xtrain.columns,class_names=bmi_labels[0:],filled=True, rounded=True)\n",
    "bmi_graph = graphviz.Source(bmi_dot_data)\n",
    "#graph.render(\"BMI\")\n",
    "bmi_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
