{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Begin prepare_data\n",
      "X_train shape: (7445, 92)\n",
      "X_test shape: (3192, 92)\n",
      "y_train shape: (7445,)\n",
      "y_test shape: (3192,)\n",
      "End prepare_data()\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH = '../data/ehresp_2014.xlsx'\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the ehresp_2014 DataFrame\n",
    "ehresp_2014 = pd.read_excel(FILE_PATH)\n",
    "\n",
    "from enum import Enum\n",
    "class FEATURE_SELECTION_OPTIONS(Enum):\n",
    "    K_BEST = 'k_best',\n",
    "    NONE = 'none'\n",
    "\n",
    "def do_the_stuff(feature_selection_option):\n",
    "    from enum import Enum\n",
    "    class COLUMN_TYPES(Enum):\n",
    "        NUMERICAL = 'numerical',\n",
    "        CATEGORICAL = 'categorical'\n",
    "\n",
    "    numerical_columns = ['ertpreat', \\\n",
    "                         'ertseat', \\\n",
    "                         'euexfreq', \\\n",
    "                         'eufastfdfrq']\n",
    "\n",
    "    categorical_columns = ['eeincome1', \\\n",
    "                           'erhhch', \\\n",
    "                           'erincome', \\\n",
    "                           'erspemch', \\\n",
    "                           'eudietsoda', \\\n",
    "                           'eudrink', \\\n",
    "                           'eueat', \\\n",
    "                           'euexercise', \\\n",
    "                           'eufastfd', \\\n",
    "                           'euffyday', \\\n",
    "                           'eufdsit', \\\n",
    "                           'eusnap', \\\n",
    "                           'eugenhth', \\\n",
    "                           'eugroshp', \\\n",
    "                           'euinclvl', \\\n",
    "                           'euincome2', \\\n",
    "                           'eumeat', \\\n",
    "                           'eumilk', \\\n",
    "                           'euprpmel', \\\n",
    "                           'eusoda', \\\n",
    "                           'eustores', \\\n",
    "                           'eustreason', \\\n",
    "                           'eutherm', \\\n",
    "                           'euwic']\n",
    "\n",
    "    target_column = 'erbmi'\n",
    "    \n",
    "    def drop_records_with_negagive_values_in_column(dataset, col):\n",
    "        return dataset.loc[dataset[col] >= 0]\n",
    "\n",
    "    def split_data(dataset):\n",
    "        import numpy as np\n",
    "        length = dataset.shape[0]\n",
    "        train_index_stop = int(length * 0.7)\n",
    "        permutation = np.random.RandomState(0).permutation(length)\n",
    "\n",
    "        # Take just the values up to the train_index_stop\n",
    "        train_permutation = permutation[:train_index_stop]\n",
    "        # Take the values after the train_index_stop\n",
    "        test_permutation = permutation[train_index_stop:]\n",
    "\n",
    "        # Create the training and testing data\n",
    "        dataset_train = dataset[train_permutation]\n",
    "        dataset_test = dataset[test_permutation]\n",
    "\n",
    "        return [dataset_train, dataset_test]\n",
    "\n",
    "    def prepare_categorical_columns(dataset, columns):\n",
    "        import pandas as pd\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "        # Extract columns from dataset; convert to array\n",
    "        dataset = dataset[columns].values\n",
    "\n",
    "        # Apply LabelEncoder to multiple columns: https://stackoverflow.com/a/31939145\n",
    "        dataset = pd.DataFrame(dataset).apply(LabelEncoder().fit_transform).values\n",
    "\n",
    "        # OHE for multiple columns using pd.get_dummies: https://stackoverflow.com/a/44601764\n",
    "        # Another get_dummies example: http://queirozf.com/entries/one-hot-encoding-a-feature-on-a-pandas-dataframe-an-example\n",
    "        # OHE vs. get_dummies: https://medium.com/@guaisang/handling-categorical-features-get-dummies-onehotencoder-and-multicollinearity-f9d473a40417\n",
    "        dataset_df = pd.DataFrame(dataset, columns=columns)\n",
    "        # Keep only the columns we want, and drop the extraneous dummy column\n",
    "        dataset_dummies = pd.get_dummies(dataset_df,\n",
    "                                         columns=columns,\n",
    "                                         drop_first=True)\n",
    "        dataset = dataset_dummies.values\n",
    "\n",
    "        # Split dataset\n",
    "        dataset_train, dataset_test = split_data(dataset)\n",
    "\n",
    "        return [dataset_train, dataset_test]\n",
    "\n",
    "    def prepare_numerical_columns(dataset, columns):\n",
    "        # Extract columns from dataset; convert to array\n",
    "        dataset = dataset[columns].values\n",
    "\n",
    "        # Split dataset\n",
    "        X_train, X_test = split_data(dataset)\n",
    "\n",
    "        # Scale values\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        sc_X = StandardScaler()\n",
    "        X_train = sc_X.fit_transform(X_train)\n",
    "        X_test = sc_X.transform(X_test)\n",
    "\n",
    "        return [X_train, X_test]\n",
    "\n",
    "    # Define a function to return BMI class\n",
    "    def get_bmi_class(bmi):\n",
    "        if bmi < 18.5:\n",
    "            return 'Underweight'\n",
    "        elif bmi >= 18.5 and  bmi < 25:\n",
    "            return 'Normal'\n",
    "        elif bmi >= 25 and bmi < 30:\n",
    "            return 'Overweight'\n",
    "        elif bmi >= 30:\n",
    "            return 'Obese'\n",
    "        else:\n",
    "            return 'Unknown'\n",
    "\n",
    "    def prepare_target_column(dataset, column, return_column_type):\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        dataset = dataset[column].values\n",
    "\n",
    "        if (return_column_type == COLUMN_TYPES.CATEGORICAL):\n",
    "            dataset = np.asarray(pd.Series(get_bmi_class(bmi) for bmi in dataset))\n",
    "\n",
    "        # Split dataset\n",
    "        dataset_train, dataset_test = split_data(dataset)\n",
    "\n",
    "        return [dataset_train, dataset_test]\n",
    "\n",
    "\n",
    "    def prepare_data(dataset,\n",
    "                     categorical_columns,\n",
    "                     numerical_columns,\n",
    "                     target_column,\n",
    "                     target_column_return_type):\n",
    "        print('\\nBegin prepare_data')\n",
    "        import pandas as pd\n",
    "        \n",
    "        dataset = drop_records_with_negagive_values_in_column(dataset, target_column)\n",
    "        \n",
    "        X_categorical_train, \\\n",
    "        X_categorical_test = prepare_categorical_columns(dataset, categorical_columns)\n",
    "\n",
    "        X_numerical_train, \\\n",
    "        X_numerical_test = \\\n",
    "        prepare_numerical_columns(dataset, numerical_columns)\n",
    "\n",
    "        X_train = pd.DataFrame(X_numerical_train) \\\n",
    "        .merge(pd.DataFrame(X_categorical_train),\n",
    "               how='outer',\n",
    "               left_index=True,\n",
    "               right_index=True) \\\n",
    "        .values\n",
    "        print('X_train shape:', X_train.shape)\n",
    "\n",
    "        X_test = pd.DataFrame(X_numerical_test) \\\n",
    "        .merge(pd.DataFrame(X_categorical_test),\n",
    "               how='outer',\n",
    "               left_index=True,\n",
    "               right_index=True) \\\n",
    "        .values\n",
    "        print('X_test shape:', X_test.shape)\n",
    "\n",
    "        y_train, \\\n",
    "        y_test = \\\n",
    "        prepare_target_column(dataset, target_column, target_column_return_type)\n",
    "\n",
    "        print('y_train shape:', y_train.shape)\n",
    "        print('y_test shape:', y_test.shape)\n",
    "\n",
    "        print('End prepare_data()\\n')\n",
    "        return [X_train, X_test, y_train, y_test]\n",
    "\n",
    "    X_train, X_test, \\\n",
    "    y_train, y_test = \\\n",
    "    prepare_data(dataset = ehresp_2014,\n",
    "                 categorical_columns = categorical_columns,\n",
    "                 numerical_columns = numerical_columns,\n",
    "                 target_column = target_column,\n",
    "                 target_column_return_type = COLUMN_TYPES.CATEGORICAL)\n",
    "\n",
    "    if(feature_selection_option == FEATURE_SELECTION_OPTIONS.K_BEST):\n",
    "        def select_k_best_categorical_features(X_train,\n",
    "                                               y_train,\n",
    "                                               X_test,\n",
    "                                               first_categorical_column_index,\n",
    "                                               k_best,\n",
    "                                               score_function):\n",
    "            print('\\nBegin select_k_best_categorical_features()')\n",
    "            from sklearn.feature_selection import SelectKBest\n",
    "            import numpy as np\n",
    "\n",
    "            print('Before selection: X_train.shape', X_train.shape)\n",
    "\n",
    "            select_k_best = SelectKBest(score_func = score_function, k = k_best)\n",
    "            fit = select_k_best.fit(X_train[:, first_categorical_column_index:], y_train)\n",
    "\n",
    "            def transform(arr, fit, first_categorical_column_index):\n",
    "                arr_numerical = arr[:, :first_categorical_column_index]\n",
    "                arr_categorical = arr[:, first_categorical_column_index:]\n",
    "                features = fit.transform(arr_categorical)\n",
    "                return np.append(arr_numerical, features, axis=1)\n",
    "\n",
    "            X_train = transform(arr = X_train,\n",
    "                                fit = fit,\n",
    "                                first_categorical_column_index = first_categorical_column_index)\n",
    "\n",
    "            print('After selection: X_train.shape', X_train.shape)\n",
    "            print('After selection: X_train:\\n', X_train)\n",
    "\n",
    "            print('Before selection: X_test.shape', X_test.shape)\n",
    "            X_test = transform(arr = X_test,\n",
    "                               fit = fit,\n",
    "                               first_categorical_column_index = first_categorical_column_index)\n",
    "            print('After selection: X_test.shape', X_test.shape)\n",
    "            print('After selection: X_test:\\n', X_test)\n",
    "\n",
    "            print('End select_k_best_categorical_features()\\n')\n",
    "            return [X_train, X_test]\n",
    "\n",
    "\n",
    "        # https://www.datacamp.com/community/tutorials/feature-selection-python\n",
    "        # Note that `chi2` works _only_ for non-negative categorical data\n",
    "        from sklearn.feature_selection import chi2\n",
    "\n",
    "        X_train, X_test = select_k_best_categorical_features(X_train = X_train,\n",
    "                                                             y_train = y_train,\n",
    "                                                             X_test = X_test,\n",
    "                                                             first_categorical_column_index = 4, \n",
    "                                                             k_best = 25,\n",
    "                                                             score_function = chi2)\n",
    "        \n",
    "    \n",
    "    return [X_train, X_test, y_train, y_test]\n",
    "\n",
    "X_train, X_test, \\\n",
    "y_train, y_test = do_the_stuff(feature_selection_option = FEATURE_SELECTION_OPTIONS.NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Feature Elimination with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_optimum_features(X_train,\n",
    "                         y_train,\n",
    "                         estimator,\n",
    "                         cv,\n",
    "                         scoring):\n",
    "    # https://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html\n",
    "    from sklearn.feature_selection import RFECV\n",
    "\n",
    "    rfecv = RFECV(estimator,\n",
    "                  step = 1,\n",
    "                  cv = cv,\n",
    "                  scoring = scoring\n",
    "                 )\n",
    "\n",
    "    rfecv.fit(X_train, y_train)\n",
    "    \n",
    "    # Plot number of features VS. cross-validation scores\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "    plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "    plt.show()\n",
    "    \n",
    "    import numpy as np\n",
    "    print('The highest accuracy, %2.4f, is achieved with %2d features.' % (np.amax(rfecv.grid_scores_), np.argmax(rfecv.grid_scores_)))\n",
    "    \n",
    "    print('Ranking of features (`1` indicates selected):\\n', rfecv.ranking_)\n",
    "    \n",
    "    return rfecv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimator:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEbCAYAAAArhqjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest accuracy, 0.4572, is achieved with 68 features.\n",
      "Ranking of features (`1` indicates selected):\n",
      " [18 22  6 16 21 24  1  1  1  1 17 13  3  1 14  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  5 12  1  1  1  1  1  1  1  1  1  1  1 11  1  1 10  1\n",
      "  1  1  1  1  1 19  1  1  4 20  1  1  1  1  1  1  1  1  2  1  1  1  1  1\n",
      "  1  1  1 23  1  1  1  1  7  9  8  1  1 15  1  1  1  1  1  1]\n",
      "\n",
      "Estimator:  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression (from bmiClassify)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegression = LogisticRegression(random_state=0)\n",
    "\n",
    "# Support Vector Machine: linear\n",
    "from sklearn.svm import SVC\n",
    "svc_linear = SVC(kernel='linear')\n",
    "\n",
    "# Support Vector Machine: rbf\n",
    "from sklearn.svm import SVC\n",
    "svc_rbf = SVC(kernel='rbf')\n",
    "\n",
    "estimators = [logisticRegression,\n",
    "              svc_linear,           \n",
    "              svc_rbf]\n",
    "outputs = {}\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(2)\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for estimator in estimators:\n",
    "    print('\\nEstimator: ', estimator)\n",
    "    output = get_optimum_features(X_train,\n",
    "                                  y_train,\n",
    "                                  estimator, \n",
    "                                  cv,\n",
    "                                  scoring)\n",
    "    outputs[estimator] = output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'criterion': 'entropy', 'n_estimators': 50}\n",
      "0.4116856950973808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randomForestClassifier = RandomForestClassifier(random_state = RANDOM_STATE)\n",
    "\n",
    "estimator = randomForestClassifier\n",
    "\n",
    "grid_param = {\\\n",
    "              'n_estimators': [10, 15, 20, 25, 30, 40, 50], \\\n",
    "              'criterion': ['gini', 'entropy'], \\\n",
    "              'bootstrap': [True, False] \\\n",
    "             }\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gd_sr = GridSearchCV(estimator = estimator,\n",
    "                     param_grid = grid_param,\n",
    "                     scoring = 'accuracy',\n",
    "                     cv = 5,\n",
    "                     n_jobs = -1)\n",
    "\n",
    "gd_sr.fit(X_train, y_train)\n",
    "print(gd_sr.best_params_)\n",
    "print(gd_sr.best_score_)\n",
    "\n",
    "# {'bootstrap': True, 'criterion': 'entropy', 'n_estimators': 50}\n",
    "# 0.4116856950973808"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'minkowski', 'n_neighbors': 10, 'p': 3}\n",
      "0.3815983881799866\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "estimator = KNeighborsClassifier() # Does not accept random_state\n",
    "\n",
    "grid_param = {\\\n",
    "              'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10], \\\n",
    "              'p': [1, 2, 3],\n",
    "              'metric': ['minkowski', 'euclidean', 'manhattan'] \\\n",
    "             }\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gd_sr = GridSearchCV(estimator = estimator,\n",
    "                     param_grid = grid_param,\n",
    "                     scoring = 'accuracy',\n",
    "                     cv = 5,\n",
    "                     n_jobs = -1)\n",
    "\n",
    "gd_sr.fit(X_train, y_train)\n",
    "print(gd_sr.best_params_)\n",
    "print(gd_sr.best_score_)\n",
    "\n",
    "# {'metric': 'minkowski', 'n_neighbors': 10, 'p': 3}\n",
    "# 0.3815983881799866"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/ehelander/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.46178643384822027\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "estimator = LogisticRegression(random_state = RANDOM_STATE)\n",
    "\n",
    "grid_param = {\\\n",
    "              'penalty': ['l2'], \\\n",
    "              'C': [0.001, 0.01, 0.1, 1, 10, 100], \\\n",
    "              'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "             }\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gd_sr = GridSearchCV(estimator = estimator,\n",
    "                     param_grid = grid_param,\n",
    "                     scoring = 'accuracy',\n",
    "                     cv = 5,\n",
    "                     n_jobs = -1)\n",
    "\n",
    "gd_sr.fit(X_train, y_train)\n",
    "print(gd_sr.best_params_)\n",
    "print(gd_sr.best_score_)\n",
    "\n",
    "# {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
    "# 0.46178643384822027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'degree': 2, 'kernel': 'rbf'}\n",
      "0.4495634654130289\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "estimator = SVC(random_state = RANDOM_STATE)\n",
    "\n",
    "grid_param = {\\\n",
    "              'kernel': ['rbf', 'linear', 'poly', 'sigmoid'], \\\n",
    "              'degree': [2, 3, 4] \\\n",
    "             }\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gd_sr = GridSearchCV(estimator = estimator,\n",
    "                     param_grid = grid_param,\n",
    "                     scoring = 'accuracy',\n",
    "                     cv = 5,\n",
    "                     n_jobs = -1)\n",
    "\n",
    "gd_sr.fit(X_train, y_train)\n",
    "print(gd_sr.best_params_)\n",
    "print(gd_sr.best_score_)\n",
    "\n",
    "# {'degree': 2, 'kernel': 'rbf'}\n",
    "# 0.4495634654130289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
